# Local configuration for CMS CompOps Agent
# Uses local Ollama server at localhost:11434
#
# Run with:
# export ARCHI_DIR=/tmp/archi-test
# echo "PG_PASSWORD=testpassword123" > /tmp/test-env
# archi create --name cms-agent --config examples/deployments/basic-agent/local-config.yaml --services chatbot --env-file /tmp/test-env 

name: cms_agent_local

services:
  postgres:
    port: 5432
  chat_app:
    agent_class: CMSCompOpsAgent
    agents_dir: examples/agents
    default_provider: local
    default_model: qwen3:4b
    providers:
      local:
        enabled: true
        base_url: http://host.docker.internal:11434 # Docker's way to reach localhost
        mode: ollama
        default_model: "qwen3:4b"
        models:
          - "qwen3:4b"
    trained_on: "CMS Computing Documentation"
    port: 7868
    external_port: 7868
  vectorstore:
    backend: postgres # PostgreSQL with pgvector
  data_manager:
    port: 4242
    external_port: 4242

data_manager:
  sources:
    links:
      input_lists:
        - examples/deployments/basic-agent/miscellanea.list
  embedding_name: HuggingFaceEmbeddings
  embedding_class_map:
    HuggingFaceEmbeddings:
      class: HuggingFaceEmbeddings
      kwargs:
        model_name: sentence-transformers/all-MiniLM-L6-v2
        model_kwargs:
          device: cpu
        encode_kwargs:
          normalize_embeddings: true
      similarity_score_reference: 10
